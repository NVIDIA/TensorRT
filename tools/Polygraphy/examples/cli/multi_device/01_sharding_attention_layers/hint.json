{
    "parallelism": "CP",
    "group_size": 0,
    "root": 0,
    "groups": [],
    "attention_layers": [
        {
            "q": "q",
            "gather_kv": true,
            "gather_q": false,
            "polygraphy_class": "AttentionLayerHint"
        }
    ],
    "inputs": [
        {
            "name": "input",
            "seq_len_idx": 0,
            "rank": 3,
            "polygraphy_class": "ShardTensor"
        }
    ],
    "outputs": [
        {
            "name": "output",
            "seq_len_idx": 0,
            "rank": 3,
            "polygraphy_class": "ShardTensor"
        }
    ],
    "k_seq_len_idx": 0,
    "v_seq_len_idx": 0,
    "kv_rank": null,
    "reduce_scatter_reduce_op": "max",
    "polygraphy_class": "ShardHints"
}